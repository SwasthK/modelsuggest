const MODELS = [
    "chatgpt-4o-latest",
    "claude-3-5-haiku",
    "claude-3-7-sonnet",
    "claude-3-haiku",
    "claude-haiku-4-5",
    "claude-opus-4",
    "claude-opus-4-1",
    "claude-opus-4-5",
    "claude-sonnet-4",
    "claude-sonnet-4-5",
    "codex-mini-latest",
    "cogito-v2-preview-llama-109b-moe",
    "cogito-v2-preview-llama-405b",
    "cogito-v2-preview-llama-70b",
    "deepseek",
    "deepseek-prover",
    "deepseek-r1",
    "deepseek-r1-0528",
    "deepseek-r1-0528-distill-qwen3-8b",
    "deepseek-r1-0528-fast",
    "deepseek-r1-0528-qwen3-8b",
    "deepseek-r1-0528-tput",
    "deepseek-r1-0528-turbo",
    "deepseek-r1-distill-llama-70b",
    "deepseek-r1-distill-qwen-14b",
    "deepseek-r1-distill-qwen-32b",
    "deepseek-r1-turbo",
    "deepseek-v3",
    "deepseek-v3.1",
    "deepseek-v3.1-terminus",
    "deepseek-v3.2-exp",
    "devstral-small-2505",
    "ernie-4.5-21b-a3b",
    "ernie-4.5-21b-a3b-thinking",
    "ernie-4.5-300b-a47b-paddle",
    "ernie-4.5-vl-28b-a3b",
    "ernie-4.5-vl-424b-a47b",
    "gemini-2.0-flash",
    "gemini-2.5-flash",
    "gemini-2.5-pro",
    "gemma-2-9b-it-fast",
    "gemma-3-12b-it",
    "gemma-3-27b-it",
    "gemma-3-27b-it-fast",
    "gemma-3-4b-it",
    "gemma-3n-e4b-it",
    "glm-4.1v-9b-thinking",
    "glm-4.5",
    "glm-4.5-air",
    "glm-4.5v",
    "glm-4.6",
    "gpt-3.5-turbo",
    "gpt-3.5-turbo-0125",
    "gpt-3.5-turbo-0301",
    "gpt-3.5-turbo-0613",
    "gpt-3.5-turbo-1106",
    "gpt-3.5-turbo-16k",
    "gpt-3.5-turbo-16k-0613",
    "gpt-3.5-turbo-instruct",
    "gpt-3.5-turbo-instruct-0914",
    "gpt-4",
    "gpt-4-0125-preview",
    "gpt-4-0314",
    "gpt-4-0613",
    "gpt-4-1106-preview",
    "gpt-4-1106-vision-preview",
    "gpt-4-32k",
    "gpt-4-32k-0314",
    "gpt-4-32k-0613",
    "gpt-4-turbo",
    "gpt-4-turbo-2024-04-09",
    "gpt-4-turbo-preview",
    "gpt-4-vision-preview",
    "gpt-4.1",
    "gpt-4.1-2025-04-14",
    "gpt-4.1-mini",
    "gpt-4.1-mini-2025-04-14",
    "gpt-4.1-nano",
    "gpt-4.1-nano-2025-04-14",
    "gpt-4.5-preview",
    "gpt-4.5-preview-2025-02-27",
    "gpt-4o",
    "gpt-4o-2024-05-13",
    "gpt-4o-2024-08-06",
    "gpt-4o-2024-11-20",
    "gpt-4o-audio-preview",
    "gpt-4o-audio-preview-2024-10-01",
    "gpt-4o-audio-preview-2024-12-17",
    "gpt-4o-audio-preview-2025-06-03",
    "gpt-4o-mini",
    "gpt-4o-mini-2024-07-18",
    "gpt-4o-mini-audio-preview",
    "gpt-4o-mini-audio-preview-2024-12-17",
    "gpt-4o-mini-realtime-preview",
    "gpt-4o-mini-realtime-preview-2024-12-17",
    "gpt-4o-mini-search-preview",
    "gpt-4o-mini-search-preview-2025-03-11",
    "gpt-4o-mini-transcribe",
    "gpt-4o-mini-tts",
    "gpt-4o-realtime-preview",
    "gpt-4o-realtime-preview-2024-10-01",
    "gpt-4o-realtime-preview-2024-12-17",
    "gpt-4o-realtime-preview-2025-06-03",
    "gpt-4o-search-preview",
    "gpt-4o-search-preview-2025-03-11",
    "gpt-4o-transcribe",
    "gpt-5",
    "gpt-5-2025-08-07",
    "gpt-5-chat",
    "gpt-5-chat-latest",
    "gpt-5-codex",
    "gpt-5-mini",
    "gpt-5-mini-2025-08-07",
    "gpt-5-nano",
    "gpt-5-nano-2025-08-07",
    "gpt-5-pro",
    "gpt-5-pro-2025-10-06",
    "gpt-5.1",
    "gpt-5.1-2025-11-13",
    "gpt-5.1-chat",
    "gpt-5.1-chat-latest",
    "gpt-5.1-codex",
    "gpt-5.1-codex-mini",
    "gpt-5.2",
    "gpt-5.2-chat-latest",
    "gpt-5.2-pro",
    "gpt-image-1-mini",
    "gpt-oss-120b",
    "gpt-oss-120b-turbo",
    "gpt-oss-20b",
    "gpt-oss-20b-eagle3",
    "gpt-oss-safeguard-20b",
    "gpt-realtime",
    "gpt-realtime-2025-08-28",
    "gpt-realtime-mini",
    "grok-2",
    "grok-2-1212",
    "grok-2-vision",
    "grok-2-vision-1212",
    "grok-3",
    "grok-3-beta",
    "grok-3-fast-beta",
    "grok-3-fast-latest",
    "grok-3-latest",
    "grok-3-mini",
    "grok-3-mini-beta",
    "grok-3-mini-fast",
    "grok-3-mini-fast-beta",
    "grok-3-mini-fast-latest",
    "grok-3-mini-latest",
    "grok-4",
    "grok-4-0709",
    "grok-4-1-fast",
    "grok-4-1-fast-non-reasoning",
    "grok-4-1-fast-non-reasoning-latest",
    "grok-4-1-fast-reasoning",
    "grok-4-1-fast-reasoning-latest",
    "grok-4-fast-non-reasoning",
    "grok-4-fast-reasoning",
    "grok-code-fast",
    "grok-code-fast-1",
    "grok-code-fast-1-0825",
    "hermes-2-pro-llama-3-8b",
    "hermes-3-llama-3.1-405b",
    "hermes-3-llama-3.1-70b",
    "hermes-4-405b",
    "hermes-4-70b",
    "internvl3-78b",
    "kimi-k2-0905",
    "kimi-k2-instruct",
    "kimi-k2-instruct-0905",
    "kimi-k2-thinking",
    "l3-70b-euryale-v2.1",
    "l3-8b-lunaris",
    "l3-8b-stheno-v3.2",
    "l31-70b-euryale-v2.2",
    "llama-3-70b-chat-hf",
    "llama-3-70b-instruct",
    "llama-3-8b-instruct",
    "llama-3.1-405b-instruct",
    "llama-3.1-8b-instant",
    "llama-3.1-8b-instruct",
    "llama-3.1-nemotron-70b-instruct",
    "llama-3.2-11b-vision-instruct",
    "llama-3.2-1b-instruct",
    "llama-3.2-3b-instruct",
    "llama-3.2-3b-instruct-turbo",
    "llama-3.3-70b",
    "llama-3.3-70b-instruct",
    "llama-3.3-70b-instruct-fast",
    "llama-3.3-70b-instruct-turbo",
    "llama-3.3-70b-versatile",
    "llama-3.3-nemotron-super-49b-v1.5",
    "llama-4-maverick-17b-128e-instruct",
    "llama-4-maverick-17b-128e-instruct-fp8",
    "llama-4-scout-17b-16e-instruct",
    "llama-guard-2-8b",
    "llama-guard-3-8b",
    "llama-guard-4-12b",
    "llama-v3p1-405b-instruct",
    "llama3.1-8b",
    "meta-llama-3-70b-instruct-turbo",
    "meta-llama-3-8b-instruct",
    "meta-llama-3-8b-instruct-lite",
    "meta-llama-3-8b-instruct-turbo",
    "meta-llama-3.1-405b-instruct-lite-pro",
    "meta-llama-3.1-405b-instruct-turbo",
    "meta-llama-3.1-70b-instruct",
    "meta-llama-3.1-70b-instruct-reference",
    "meta-llama-3.1-70b-instruct-turbo",
    "meta-llama-3.1-8b-instruct",
    "meta-llama-3.1-8b-instruct-turbo",
    "meta-llama-guard-3-8b",
    "minimax-m1-80k",
    "minimax-m2",
    "mistral-7b-instruct-v0.2",
    "mistral-7b-instruct-v0.3",
    "mistral-nemo",
    "mistral-nemo-instruct-2407",
    "mistral-small-24b-instruct-2501",
    "mistral-small-3.2-24b-instruct-2506",
    "mixtral-8x22b-instruct",
    "mixtral-8x7b-instruct",
    "mixtral-8x7b-instruct-v0.1",
    "mythomax-l2-13b",
    "nvidia-nemotron-nano-12b-v2-vl",
    "nvidia-nemotron-nano-9b",
    "o1",
    "o1-2024-12-17",
    "o1-preview",
    "o1-pro",
    "o1-pro-2025-03-19",
    "o3",
    "o3-2025-04-16",
    "o3-deep-research",
    "o3-deep-research-2025-06-26",
    "o3-mini",
    "o3-mini-2025-01-31",
    "o3-pro",
    "o3-pro-2025-06-10",
    "o4-mini",
    "o4-mini-2025-04-16",
    "o4-mini-deep-research",
    "o4-mini-deep-research-2025-06-26",
    "phi-3-mini-128k-instruct",
    "phi-4",
    "qwen-2.5-72b-instruct",
    "qwen-3-32b",
    "qwen2.5-72b-instruct-turbo",
    "qwen2.5-7b-instruct-turbo",
    "qwen2.5-vl-32b-instruct",
    "qwen2.5-vl-72b-instruct",
    "qwen3-14b",
    "qwen3-235b-a22b",
    "qwen3-235b-a22b-thinking-2507",
    "qwen3-30b-a3b",
    "qwen3-30b-a3b-instruct-2507",
    "qwen3-30b-a3b-thinking-2507",
    "qwen3-32b",
    "qwen3-8b",
    "qwen3-coder-30b-a3b-instruct",
    "qwen3-embedding-8b",
    "qwen3-max",
    "qwen3-next-80b-a3b-instruct",
    "qwen3-next-80b-a3b-thinking",
    "qwen3-vl-235b-a22b-instruct",
    "qwen3-vl-235b-a22b-thinking",
    "qwen3-vl-30b-a3b-instruct",
    "qwen3-vl-30b-a3b-thinking",
    "qwen3-vl-8b-instruct",
    "qwq-32b",
    "text-embedding-3-large",
    "text-embedding-3-small",
    "text-embedding-ada",
    "wizardlm-2-8x22b"
] as const;

export type Model = (typeof MODELS)[number];

export const model = MODELS.reduce((acc, m) => {
    acc[m] = m;
    return acc;
}, {} as Record<Model, Model>);

